# ADR-003 - EstratÃ©gia de Performance Multi-Camadas

**Status**: âœ… Aprovado
**Data**: 2025-10-24
**Decisores**: JosÃ© LuÃ­s Silva (CTO), NEXUS (Solution Architect)
**Contexto**: Fase de EspecificaÃ§Ã£o do Projeto DICT LBPay

---

## Contexto

### Requisito CrÃ­tico de Performance

**DeclaraÃ§Ã£o do CTO** (conforme DUVIDAS.md - DUV-012):

> "**NEW CRITICAL REQUIREMENT**: High volume of DICT queries expected **(dozens per second)**"
>
> "Emphasized **performance is critical**"

### Requisitos NÃ£o-Funcionais

| ID | Requisito | Valor | Prioridade |
|----|-----------|-------|------------|
| **RNF-001** | LatÃªncia P99 para consultas (GET /entries/{Key}) | < 1s | ğŸ”´ CrÃ­tico |
| **RNF-002** | Throughput mÃ­nimo | **Dezenas de queries/segundo** | ğŸ”´ CrÃ­tico |
| **RNF-003** | Cache hit ratio | > 70% | ğŸŸ  Alto |
| **RNF-004** | Connection pool reutilizaÃ§Ã£o | > 90% | ğŸŸ  Alto |

### SituaÃ§Ã£o Atual (AS-IS)

**Sem estratÃ©gia de cache estruturada**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ GET /entries/{Key}
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚money-moving â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ SEMPRE faz chamada ao DICT Bacen (sem cache!)
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     mTLS handshake: 100-300ms
â”‚ DICT Bacen   â”‚     Network RTT: 50-100ms
â”‚              â”‚     Processing: 50-150ms
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
LATÃŠNCIA TOTAL: 200-550ms (P99) âŒ RUIM!
```

**Problemas identificados**:

1. âŒ **Sem cache**: Toda consulta vai ao DICT Bacen
2. âŒ **mTLS handshake repetido**: ConexÃµes nÃ£o reutilizadas (100-300ms por request)
3. âŒ **Alto custo de rede**: LatÃªncia RTT Brasil-Bacen (50-100ms)
4. âŒ **Rate limiting vulnerÃ¡vel**: Facilmente atinge 429 (balde esgota rÃ¡pido)
5. âŒ **Throughput limitado**: Max 2-25k req/min (conforme categoria PSP)

**Exemplo real** (sem cache):
```
100 consultas/segundo = 6.000 consultas/minuto

Categoria E (LBPay?): 2.500/min de limite
âŒ ESTOURA rate limiting em 25 segundos!

Resultado: HTTP 429 (Rate Limited) â†’ indisponibilidade para usuÃ¡rios
```

---

## DecisÃ£o

Implementar **estratÃ©gia de performance multi-camadas** com **5 caches Redis especializados** + **connection pooling agressivo**.

### Arquitetura de Performance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚ GET /entries/{Key}?taxIdNumber=123
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core DICT Service                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         CAMADA 1: Response Cache (Redis 7001)      â”‚    â”‚
â”‚  â”‚  Key: cache-dict-response:{keyType}:{key}:{taxId} â”‚    â”‚
â”‚  â”‚  TTL: 5 minutos                                    â”‚    â”‚
â”‚  â”‚  Hit Rate esperado: 70-80%                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚ MISS                             â”‚
â”‚                           â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚    CAMADA 2: Key Validation Cache (Redis 7003)     â”‚    â”‚
â”‚  â”‚  Key: cache-dict-key-validation:{key}             â”‚    â”‚
â”‚  â”‚  TTL: 10 minutos                                   â”‚    â”‚
â”‚  â”‚  Hit Rate esperado: 50-60%                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚ MISS                             â”‚
â”‚                           â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         CAMADA 3: Deduplication (Redis 7004)       â”‚    â”‚
â”‚  â”‚  Previne requisiÃ§Ãµes duplicadas (RequestId)       â”‚    â”‚
â”‚  â”‚  TTL: 1 minuto                                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚ Not duplicate                    â”‚
â”‚                           â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      CAMADA 4: Rate Limit Local (Redis 7005)       â”‚    â”‚
â”‚  â”‚  Token Bucket local (previne 429 do Bacen)        â”‚    â”‚
â”‚  â”‚  PolÃ­ticas: ENTRIES_READ_USER_ANTISCAN, etc       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚ Tokens available                 â”‚
â”‚                           â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   CAMADA 5: Connection Pool (HTTP Keep-Alive)      â”‚    â”‚
â”‚  â”‚  Reutiliza conexÃµes mTLS                           â”‚    â”‚
â”‚  â”‚  Evita handshake (100-300ms â†’ 0ms)                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ Chamada real ao Bacen (apenas se MISS em todas as camadas)
                            â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ DICT Bacen   â”‚
                   â”‚ (API v2.6.1) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LATÃŠNCIA COM CACHE HIT (Camada 1): 5-20ms (P99) âœ… EXCELENTE!
LATÃŠNCIA COM CACHE MISS: 150-300ms (P99) âœ… BOM!
```

---

## Detalhamento das Camadas

### Camada 1: Response Cache (Redis Port 7001)

**PropÃ³sito**: Cache de respostas completas do DICT Bacen.

#### ConfiguraÃ§Ã£o

```yaml
redis:
  host: cache-dict-response
  port: 7001
  db: 0
  maxRetries: 3
  poolSize: 100
  minIdleConns: 10
  maxConnAge: 30m
  poolTimeout: 4s
  idleTimeout: 5m
  idleCheckFrequency: 1m
```

#### Schema de Keys

```
Formato: cache-dict-response:{keyType}:{key}:{taxIdNumber}

Exemplos:
- cache-dict-response:PHONE:+5561988880000:11122233300
- cache-dict-response:CPF:12345678901:12345678901
- cache-dict-response:EMAIL:user@example.com:98765432100
```

**Motivo do esquema**: Diferentes usuÃ¡rios consultando mesma chave devem ter cache separado (requisito de seguranÃ§a anti-scan).

#### Value (JSON)

```json
{
  "key": "+5561988880000",
  "keyType": "PHONE",
  "account": {
    "participant": "12345678",
    "branch": "0001",
    "accountNumber": "0007654321",
    "accountType": "CACC"
  },
  "owner": {
    "type": "NATURAL_PERSON",
    "taxIdNumber": "11122233300",
    "name": "JoÃ£o Silva"
  },
  "cachedAt": "2023-10-24T10:00:00Z"
}
```

#### TTL: 5 minutos

**Justificativa**:
- âœ… Balanceamento entre freshness e performance
- âœ… Dados de chaves PIX mudam pouco (atualizaÃ§Ãµes sÃ£o raras)
- âœ… 5min Ã© suficiente para absorver mÃºltiplas consultas ao mesmo vÃ­nculo

#### InvalidaÃ§Ã£o

**Eventos que invalidam cache**:
1. âœ… **AtualizaÃ§Ã£o de vÃ­nculo** (updateEntry)
2. âœ… **ExclusÃ£o de vÃ­nculo** (deleteEntry)
3. âœ… **Claim completado** (chave mudou de PSP)
4. âœ… **Evento CID** (via Pulsar consumer)

```go
// InvalidaÃ§Ã£o automÃ¡tica
func (uc *UpdatePixKeyUseCase) Execute(ctx context.Context, input UpdatePixKeyInput) error {
    // ... atualizaÃ§Ã£o no DICT Bacen e PostgreSQL

    // Invalidar cache
    cacheKey := fmt.Sprintf("cache-dict-response:%s:%s:*", input.KeyType, input.Key)
    uc.cache.DelPattern(ctx, cacheKey) // Remove todas as variaÃ§Ãµes (wildcard no taxIdNumber)

    return nil
}
```

#### Hit Rate Esperado: 70-80%

**CÃ¡lculo**:
```
CenÃ¡rio tÃ­pico:
- 1000 chaves PIX consultadas
- 700-800 sÃ£o consultas repetidas (mesmo key + taxIdNumber) dentro de 5min
- Hit rate = 70-80%

BenefÃ­cio:
- Sem cache: 1000 chamadas ao DICT Bacen
- Com cache: 200-300 chamadas ao DICT Bacen
- ReduÃ§Ã£o: 70-80% de chamadas
```

#### ImplementaÃ§Ã£o

```go
// pkg/infrastructure/cache/response_cache.go

type ResponseCache struct {
    client *redis.Client
}

func (c *ResponseCache) Get(ctx context.Context, keyType, key, taxIdNumber string) (*domain.PixKey, error) {
    cacheKey := fmt.Sprintf("cache-dict-response:%s:%s:%s", keyType, key, taxIdNumber)

    val, err := c.client.Get(ctx, cacheKey).Result()
    if err == redis.Nil {
        return nil, ErrCacheMiss
    }
    if err != nil {
        return nil, err
    }

    var pixKey domain.PixKey
    if err := json.Unmarshal([]byte(val), &pixKey); err != nil {
        return nil, err
    }

    return &pixKey, nil
}

func (c *ResponseCache) Set(ctx context.Context, pixKey *domain.PixKey) error {
    cacheKey := fmt.Sprintf("cache-dict-response:%s:%s:%s",
        pixKey.KeyType, pixKey.Key, pixKey.Owner.TaxIdNumber)

    data, err := json.Marshal(pixKey)
    if err != nil {
        return err
    }

    return c.client.Set(ctx, cacheKey, data, 5*time.Minute).Err()
}

func (c *ResponseCache) DelPattern(ctx context.Context, pattern string) error {
    iter := c.client.Scan(ctx, 0, pattern, 0).Iterator()
    for iter.Next(ctx) {
        if err := c.client.Del(ctx, iter.Val()).Err(); err != nil {
            return err
        }
    }
    return iter.Err()
}
```

---

### Camada 2: Key Validation Cache (Redis Port 7003)

**PropÃ³sito**: Cache de validaÃ§Ãµes de chaves (formato, existÃªncia, CPF/CNPJ).

#### Schema de Keys

```
cache-dict-key-validation:{key}

Exemplos:
- cache-dict-key-validation:+5561988880000
- cache-dict-key-validation:12345678901
```

#### Value (JSON)

```json
{
  "key": "+5561988880000",
  "isValid": true,
  "keyType": "PHONE",
  "cpfCnpjValid": true,
  "validatedAt": "2023-10-24T10:00:00Z"
}
```

#### TTL: 10 minutos

**Justificativa**:
- âœ… ValidaÃ§Ãµes de formato sÃ£o determinï¿½ï¿½sticas (nÃ£o mudam)
- âœ… ValidaÃ§Ãµes CPF/CNPJ na Receita Federal mudam raramente
- âœ… 10min balanceia freshness e reduÃ§Ã£o de chamadas Ã  Receita Federal

#### Hit Rate Esperado: 50-60%

**BenefÃ­cio**: Reduz chamadas Ã  API da Receita Federal (que pode ter rate limiting prÃ³prio).

---

### Camada 3: Deduplication Cache (Redis Port 7004)

**PropÃ³sito**: Prevenir requisiÃ§Ãµes duplicadas (idempotÃªncia).

#### Schema de Keys

```
cache-dict-dedup:{requestId}

Exemplo:
- cache-dict-dedup:a946d533-7f22-42a5-9a9b-e87cd55c0f4d
```

#### Value

```
SHA256(request body)
```

#### TTL: 1 minuto

**Justificativa**:
- âœ… RequestId deve ser Ãºnico por participante
- âœ… 1min Ã© suficiente para detectar duplicatas acidentais (ex: retry automÃ¡tico do cliente)
- âœ… TTL curto economiza memÃ³ria

#### Uso

```go
func (uc *CreatePixKeyUseCase) Execute(ctx context.Context, input CreatePixKeyInput) error {
    // 1. Check deduplication
    bodyHash := sha256.Sum256([]byte(input.ToJSON()))
    cacheKey := fmt.Sprintf("cache-dict-dedup:%s", input.RequestId)

    cachedHash, err := uc.dedupCache.Get(ctx, cacheKey)
    if err == nil {
        if cachedHash == bodyHash {
            // Duplicate request with same RequestId and same body â†’ idempotent
            return uc.repo.FindByRequestId(ctx, input.RequestId) // Return existing result
        } else {
            // Same RequestId but different body â†’ ERROR
            return ErrRequestIdAlreadyUsed
        }
    }

    // 2. Process request...
    // 3. Save to dedup cache
    uc.dedupCache.Set(ctx, cacheKey, bodyHash, 1*time.Minute)

    return nil
}
```

---

### Camada 4: Rate Limit Local Cache (Redis Port 7005)

**PropÃ³sito**: Implementar **token bucket local** para prevenir HTTP 429 do DICT Bacen.

#### Por que Rate Limiting Local?

**Problema**:
```
Sem rate limiting local:
1. Cliente faz 100 req/seg ao Core DICT
2. Core DICT repassa todas ao DICT Bacen
3. DICT Bacen: balde esgota em segundos
4. HTTP 429 Rate Limited
5. âŒ Indisponibilidade para usuÃ¡rios
```

**SoluÃ§Ã£o**:
```
Com rate limiting local:
1. Cliente faz 100 req/seg ao Core DICT
2. Core DICT verifica balde LOCAL (Redis 7005)
3. Se tokens disponÃ­veis: repassa ao DICT Bacen
4. Se tokens esgotados: retorna 429 ANTES de chamar Bacen
5. âœ… Evita esgotar balde do Bacen
6. âœ… Fail fast (latÃªncia baixa mesmo em rate limit)
```

#### Schema de Keys

```
cache-dict-rate-limit:{policy}:{scope}

Exemplos:
- cache-dict-rate-limit:ENTRIES_READ_USER_ANTISCAN:PF:11122233300
- cache-dict-rate-limit:ENTRIES_READ_PARTICIPANT_ANTISCAN:PSP:12345678
- cache-dict-rate-limit:ENTRIES_WRITE:PSP:12345678
```

#### Value

```
NÃºmero inteiro: tokens disponÃ­veis
```

#### Algoritmo: Token Bucket

```go
type TokenBucket struct {
    Capacity     int       // Tamanho do balde
    Tokens       int       // Tokens disponÃ­veis
    RefillRate   int       // Taxa de reposiÃ§Ã£o (tokens/min)
    LastRefill   time.Time // Ãšltimo refill
}

func (tb *TokenBucket) TryAcquire(count int) bool {
    // 1. Calcular tokens a repor desde Ãºltimo refill
    now := time.Now()
    elapsed := now.Sub(tb.LastRefill).Minutes()
    tokensToAdd := int(elapsed * float64(tb.RefillRate))

    // 2. Repor tokens (max = Capacity)
    tb.Tokens = min(tb.Tokens + tokensToAdd, tb.Capacity)
    tb.LastRefill = now

    // 3. Tentar consumir
    if tb.Tokens >= count {
        tb.Tokens -= count
        return true // Sucesso
    }

    return false // Rate limited
}
```

#### SincronizaÃ§Ã£o com Bacen

**Problema**: Rate limiting local pode desincronizar com balde real do Bacen.

**SoluÃ§Ã£o**: Monitorar endpoint `/policies/{policy}` periodicamente.

```go
// Background worker (a cada 1min)
func (rl *RateLimiter) SyncWithBacen(ctx context.Context) {
    // 1. Consultar estado do balde no Bacen
    state, err := rl.dictClient.GetBucketState(ctx, "ENTRIES_WRITE")
    if err != nil {
        return
    }

    // 2. Atualizar balde local
    cacheKey := "cache-dict-rate-limit:ENTRIES_WRITE:PSP:12345678"
    rl.cache.Set(ctx, cacheKey, state.Tokens, 1*time.Minute)
}
```

#### ReposiÃ§Ã£o AutomÃ¡tica por LiquidaÃ§Ã£o SPI

**Regra especial** (conforme OpenAPI):
- âœ… **Consulta seguida de pagamento** repÃµe fichas automaticamente
- âœ… Status 200 + ordem PIX enviada: +1 ficha (PF) ou +2 fichas (PJ)

```go
// Consumidor Pulsar: topic spi-liquidation
func (c *SPIConsumer) HandleLiquidationEvent(ctx context.Context, event SPILiquidationEvent) {
    // 1. Verificar se houve consulta DICT antes do PIX
    if event.DICTQueryMade {
        // 2. Repor fichas no balde local
        cacheKey := fmt.Sprintf("cache-dict-rate-limit:ENTRIES_READ_USER_ANTISCAN:%s:%s",
            event.UserType, event.TaxIdNumber)

        tokensToAdd := 1 // PF
        if event.UserType == "PJ" {
            tokensToAdd = 2
        }

        rl.cache.IncrBy(ctx, cacheKey, tokensToAdd)
    }
}
```

**BenefÃ­cio**: UsuÃ¡rios que consultam e pagam nÃ£o esgotam balde rapidamente.

---

### Camada 5: Connection Pooling (HTTP Keep-Alive)

**PropÃ³sito**: Reutilizar conexÃµes mTLS para evitar handshake repetido (100-300ms).

#### Problema: mTLS Handshake Caro

```
Sem connection pooling:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Core DICT â”‚                           â”‚ DICT Bacen   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Request 1                              â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚ TLS Handshake (6 RTTs)                â”‚
     â”‚ Client Cert validation                â”‚
     â”‚ Server Cert validation                â”‚
     â”‚ â±ï¸  100-300ms                          â”‚
     â”‚                                        â”‚
     â”‚ HTTP GET /entries/{Key}               â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ 200 OK (50ms)                          â”‚
     â”‚                                        â”‚
     â”‚ ğŸ”´ FECHA CONEXÃƒO                       â”‚
     â”‚                                        â”‚
     â”‚ Request 2 (alguns segundos depois)    â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚ TLS Handshake NOVAMENTE (6 RTTs)      â”‚
     â”‚ â±ï¸  100-300ms (DESPERDIÃ‡ADO!)         â”‚
     ...

Total por request: 150-350ms (handshake + processing)
```

```
Com connection pooling (keep-alive):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Core DICT â”‚                           â”‚ DICT Bacen   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Request 1                              â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚ TLS Handshake (6 RTTs)                â”‚
     â”‚ â±ï¸  100-300ms (apenas 1Âª vez!)        â”‚
     â”‚                                        â”‚
     â”‚ HTTP GET /entries/{Key}               â”‚
     â”‚ Connection: keep-alive                â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ 200 OK (50ms)                          â”‚
     â”‚ Keep-Alive: timeout=60                â”‚
     â”‚                                        â”‚
     â”‚ âœ… MANTÃ‰M CONEXÃƒO ABERTA              â”‚
     â”‚                                        â”‚
     â”‚ Request 2 (alguns segundos depois)    â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚ â±ï¸  0ms handshake (reutiliza conexÃ£o!) â”‚
     â”‚ HTTP GET /entries/{Key}               â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚ 200 OK (50ms)                          â”‚
     ...

Total por request (apÃ³s 1Âª): 50-100ms (apenas processing)
ReduÃ§Ã£o: 60-85% de latÃªncia!
```

#### ConfiguraÃ§Ã£o (Go)

```go
// pkg/infrastructure/clients/connect_dict_client.go

func NewConnectDICTClient(certFile, keyFile, caFile string) (*ConnectDICTClient, error) {
    // 1. Load mTLS certificates
    cert, err := tls.LoadX509KeyPair(certFile, keyFile)
    if err != nil {
        return nil, err
    }

    caCert, err := ioutil.ReadFile(caFile)
    if err != nil {
        return nil, err
    }
    caCertPool := x509.NewCertPool()
    caCertPool.AppendCertsFromPEM(caCert)

    // 2. Configure TLS
    tlsConfig := &tls.Config{
        Certificates: []tls.Certificate{cert},
        RootCAs:      caCertPool,
        MinVersion:   tls.VersionTLS12,
    }

    // 3. Configure HTTP Transport with connection pooling
    transport := &http.Transport{
        TLSClientConfig: tlsConfig,

        // Connection pooling settings
        MaxIdleConns:        100,  // Max connections total (todos os hosts)
        MaxIdleConnsPerHost: 10,   // Max connections por host (DICT Bacen)
        MaxConnsPerHost:     20,   // Max connections ativas por host

        IdleConnTimeout:     90 * time.Second, // Timeout para conexÃµes idle
        DisableKeepAlives:   false,            // âœ… HABILITAR keep-alive
        DisableCompression:  false,            // âœ… HABILITAR compressÃ£o

        // Timeouts
        DialContext: (&net.Dialer{
            Timeout:   5 * time.Second,  // Timeout para dial
            KeepAlive: 30 * time.Second, // TCP keep-alive
        }).DialContext,
        TLSHandshakeTimeout:   10 * time.Second,
        ResponseHeaderTimeout: 5 * time.Second,
        ExpectContinueTimeout: 1 * time.Second,
    }

    // 4. Create HTTP client
    client := &http.Client{
        Transport: transport,
        Timeout:   10 * time.Second, // Timeout total do request
    }

    return &ConnectDICTClient{
        client:  client,
        baseURL: "https://dict.pi.rsfn.net.br:16422/api/v2",
    }, nil
}

func (c *ConnectDICTClient) GetEntry(ctx context.Context, key string) (*Entry, error) {
    url := fmt.Sprintf("%s/entries/%s", c.baseURL, key)

    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return nil, err
    }

    // IMPORTANTE: Header para solicitar compressÃ£o
    req.Header.Set("Accept-Encoding", "gzip")

    resp, err := c.client.Do(req) // Reutiliza conexÃ£o do pool!
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    // ... parse response
}
```

#### Monitoramento de Connection Pool

**MÃ©tricas Prometheus**:
```prometheus
# ConexÃµes ativas
dict_http_connections_active{host="dict.pi.rsfn.net.br"}

# ConexÃµes idle (disponÃ­veis para reuso)
dict_http_connections_idle{host="dict.pi.rsfn.net.br"}

# Taxa de reuso (target: > 90%)
dict_http_connection_reuse_ratio
```

**Alerta**:
```yaml
- alert: LowConnectionReuseRatio
  expr: dict_http_connection_reuse_ratio < 0.9
  for: 10m
  severity: warning
  annotations:
    summary: "Connection reuse ratio < 90% for 10 minutes"
    description: "Possible issue with keep-alive or high connection churn"
```

---

## CompressÃ£o (Adicional)

**Header de Request**:
```
Accept-Encoding: gzip
```

**BenefÃ­cio**:
- âœ… Reduz largura de banda em 60-80%
- âœ… Reduz latÃªncia de rede (menos bytes transmitidos)

**Exemplo**:
```
Resposta sem compressÃ£o: 5 KB
Resposta com gzip: 1-2 KB
ReduÃ§Ã£o: 60-80%

LatÃªncia de rede (100 Mbps):
- Sem compressÃ£o: 5 KB * 8 / 100 Mbps = 0.4ms
- Com compressÃ£o: 1.5 KB * 8 / 100 Mbps = 0.12ms
Ganho: ~0.3ms (marginal, mas todo ganho conta!)
```

---

## Resultados Esperados

### LatÃªncias (P99)

| CenÃ¡rio | Sem OtimizaÃ§Ãµes | Com OtimizaÃ§Ãµes | Melhoria |
|---------|-----------------|-----------------|----------|
| **Cache HIT (Camada 1)** | N/A | **5-20ms** | âœ… Excelente |
| **Cache MISS (primeira consulta)** | 200-550ms | **150-300ms** | 45% mais rÃ¡pido |
| **Consulta recorrente (dentro de 5min)** | 200-550ms | **5-20ms** | **90-97% mais rÃ¡pido** |

### Throughput

| MÃ©trica | Sem OtimizaÃ§Ãµes | Com OtimizaÃ§Ãµes | Melhoria |
|---------|-----------------|-----------------|----------|
| **Req/seg suportados** | 10-40 (limitado por Bacen) | **100-500** | **10-50x** |
| **Cache hit ratio** | 0% | **70-80%** | N/A |
| **Chamadas ao Bacen reduzidas** | 100% | **20-30%** | **70-80% reduÃ§Ã£o** |

### Exemplo PrÃ¡tico

**CenÃ¡rio**: 100 consultas/segundo ao mesmo conjunto de 1000 chaves PIX.

```
SEM OTIMIZAÃ‡Ã•ES:
- 100 req/seg * 60 seg = 6.000 req/min
- Categoria E (LBPay?): limite 2.500/min
- âŒ RATE LIMITED em 25 segundos
- Indisponibilidade: 75% do tempo

COM OTIMIZAÃ‡Ã•ES (70% cache hit rate):
- 100 req/seg * 60 seg = 6.000 req/seg
- Cache HIT: 4.200 req/seg (nÃ£o vÃ£o ao Bacen)
- Cache MISS: 1.800 req/seg (vÃ£o ao Bacen) â†’ 30/seg â†’ 1.800/min
- 1.800/min < 2.500/min (limite Categoria E)
- âœ… DENTRO DO LIMITE
- Disponibilidade: 100%
```

---

## ConsequÃªncias

### âœ… Positivas

1. **Performance CrÃ­tica Atendida**:
   - âœ… LatÃªncia P99 < 1s (meta: 5-20ms com cache)
   - âœ… Throughput de dezenas/centenas de req/seg

2. **ReduÃ§Ã£o de Custos**:
   - âœ… 70-80% menos chamadas ao DICT Bacen
   - âœ… Menor uso de rate limiting (evita 429)

3. **Melhor UX**:
   - âœ… Respostas instantÃ¢neas (5-20ms)
   - âœ… Menor latÃªncia percebida

4. **ResiliÃªncia**:
   - âœ… Se DICT Bacen estiver lento/indisponÃ­vel, cache absorve carga
   - âœ… DegradaÃ§Ã£o graciosa

5. **Observabilidade**:
   - âœ… MÃ©tricas de cache hit rate
   - âœ… Monitoramento de connection pool

### âš ï¸ Negativas (e MitigaÃ§Ãµes)

#### 1. Complexidade de Infraestrutura

**Problema**: 5 instÃ¢ncias Redis + lÃ³gica de invalidaÃ§Ã£o.

**MitigaÃ§Ã£o**:
- âœ… **Redis Cluster**: Gerenciamento simplificado
- âœ… **Infrastructure as Code** (Terraform): AutomaÃ§Ã£o de provisionamento
- âœ… **Helm Charts**: Deploy padronizado no Kubernetes

#### 2. Dados Potencialmente Stale

**Problema**: Cache pode retornar dados desatualizados (atÃ© 5min).

**MitigaÃ§Ã£o**:
- âœ… **InvalidaÃ§Ã£o ativa**: Eventos CID (Pulsar) invalidam cache imediatamente
- âœ… **TTL curto (5min)**: Balanceamento entre freshness e performance
- âœ… **Cache bypass**: Header `X-Cache-Control: no-cache` para forÃ§ar consulta ao Bacen

**Exemplo**:
```go
// Cliente pode forÃ§ar bypass de cache
req.Header.Set("X-Cache-Control", "no-cache")
```

#### 3. Uso de MemÃ³ria

**Problema**: 5 Redis consumindo memÃ³ria.

**CÃ¡lculo de Uso**:
```
Estimativa:
- 1 milhÃ£o de chaves PIX
- Cada entrada de cache: ~1 KB (JSON)
- Total: 1 GB de RAM (Response Cache)
- Outros caches: 200-300 MB cada
- Total: ~2.5 GB de RAM

Custo (AWS ElastiCache):
- cache.r6g.large (13.07 GB RAM): $0.201/hora
- 5 instÃ¢ncias: $0.201 * 5 = $1.005/hora
- Mensal: ~$730/mÃªs
```

**MitigaÃ§Ã£o**:
- âœ… **Eviction policy**: `allkeys-lru` (remove menos usados)
- âœ… **TTL agressivo**: Libera memÃ³ria automaticamente
- âœ… **Monitoramento**: Alerta se uso > 80%

#### 4. SincronizaÃ§Ã£o de Rate Limiting

**Problema**: Rate limiting local pode desincronizar com Bacen.

**MitigaÃ§Ã£o**:
- âœ… **Polling periÃ³dico**: `/policies/{policy}` a cada 1min
- âœ… **Ajuste conservador**: Usar 90% do limite do Bacen (margem de seguranÃ§a)
- âœ… **Backoff em 429**: Se receber 429 do Bacen, ajustar balde local imediatamente

---

## Alternativas Consideradas

### Alternativa 1: Cache Ãšnico (sem multi-camadas)

**PrÃ³s**:
- âœ… Mais simples

**Contras**:
- âŒ Hit rate menor (~40-50%)
- âŒ NÃ£o previne rate limiting local
- âŒ NÃ£o previne duplicatas

**DecisÃ£o**: âŒ Rejeitada - Performance insuficiente.

---

### Alternativa 2: Cache em MemÃ³ria (in-process)

**PrÃ³s**:
- âœ… LatÃªncia ultra-baixa (< 1ms)
- âœ… Sem dependÃªncia externa

**Contras**:
- âŒ NÃ£o compartilhado entre pods (cada pod tem cache prÃ³prio)
- âŒ Uso alto de RAM por pod
- âŒ InvalidaÃ§Ã£o complexa (precisa broadcast)

**DecisÃ£o**: âŒ Rejeitada - NÃ£o escalÃ¡vel horizontalmente.

---

### Alternativa 3: Redis Ãšnico (1 instÃ¢ncia para tudo)

**PrÃ³s**:
- âœ… Mais simples (menos instÃ¢ncias)

**Contras**:
- âŒ Single point of failure
- âŒ ContenÃ§Ã£o (todos os acessos na mesma instÃ¢ncia)
- âŒ DifÃ­cil tuning (TTLs e polÃ­ticas diferentes)

**DecisÃ£o**: âŒ Rejeitada - 5 instÃ¢ncias especializadas sÃ£o mais performÃ¡ticas.

---

## DecisÃ£o Final

âœ… **APROVADA**: Implementar **estratÃ©gia de performance multi-camadas** com **5 caches Redis especializados** + **connection pooling agressivo**.

### Justificativa

1. âœ… **Ãšnica forma de atingir RNF-002** (dezenas de queries/segundo)
2. âœ… **Reduz 70-80% de chamadas** ao DICT Bacen
3. âœ… **LatÃªncia P99 < 20ms** (com cache hit)
4. âœ… **Previne HTTP 429** (rate limiting local)
5. âœ… **Observabilidade completa** (mÃ©tricas de cada camada)
6. âœ… **EscalÃ¡vel horizontalmente** (Redis Cluster + Kubernetes HPA)

---

## ImplementaÃ§Ã£o

### Fase 1: Infraestrutura (Semana 1)

```bash
# 1. Provisionar 5 Redis (Terraform)
terraform apply -target=module.redis_cluster

# 2. Configurar Redis
kubectl apply -f k8s/redis/

# 3. Testar conectividade
make test-redis-connection
```

### Fase 2: Response Cache (Semana 2)

```bash
# Implementar Camada 1 (Response Cache)
# - pkg/infrastructure/cache/response_cache.go
# - Integrar em GetPixKeyUseCase
# - Testes unitÃ¡rios
```

### Fase 3: Camadas Restantes (Semanas 3-4)

```bash
# Implementar Camadas 2, 3, 4, 5
# - Key Validation Cache
# - Deduplication Cache
# - Rate Limit Local Cache
# - Connection Pooling
```

### Fase 4: Observabilidade (Semana 5)

```bash
# MÃ©tricas, dashboards, alertas
# - Prometheus metrics
# - Grafana dashboards
# - Alertmanager rules
```

### Fase 5: Testes de Performance (Semana 6)

```bash
# Load testing
k6 run tests/load/get_pixkey_load_test.js

# Validar:
# - LatÃªncia P99 < 20ms (cache hit)
# - Throughput > 100 req/seg
# - Cache hit rate > 70%
```

---

## Monitoramento

### MÃ©tricas Chave

```prometheus
# Cache performance
dict_cache_hit_ratio{cache="response"} > 0.7
dict_cache_latency_seconds{cache="response", quantile="0.99"} < 0.020

# Connection pool
dict_http_connection_reuse_ratio > 0.9
dict_http_connections_active < 50

# Rate limiting
dict_rate_limited_requests_total < 10/hour
```

### Dashboards Grafana

1. **Cache Performance Dashboard**
   - Hit rate por cache (5 grÃ¡ficos)
   - LatÃªncia P50/P95/P99
   - Memory usage

2. **Connection Pool Dashboard**
   - ConexÃµes ativas vs idle
   - Taxa de reuso
   - Handshake time

3. **Rate Limiting Dashboard**
   - Tokens disponÃ­veis por polÃ­tica
   - RequisiÃ§Ãµes rate limited
   - SincronizaÃ§Ã£o com Bacen

---

## ReferÃªncias

1. **Token Bucket Algorithm**
   https://en.wikipedia.org/wiki/Token_bucket

2. **HTTP Keep-Alive**
   https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Keep-Alive

3. **Redis Best Practices**
   https://redis.io/docs/management/optimization/

4. **Go HTTP Transport Tuning**
   https://golang.org/pkg/net/http/#Transport

5. **API-001** - EspecificaÃ§Ã£o de APIs DICT Bacen (Rate Limiting)
   [Artefatos/04_APIs/API-001_Especificacao_APIs_DICT_Bacen.md](../04_APIs/API-001_Especificacao_APIs_DICT_Bacen.md#52-todas-as-polÃ­ticas-de-rate-limiting)

6. **DAS-001** - Arquitetura de SoluÃ§Ã£o TO-BE (Performance)
   [Artefatos/02_Arquitetura/DAS-001_Arquitetura_Solucao_TO_BE.md](DAS-001_Arquitetura_Solucao_TO_BE.md#9-estratÃ©gia-de-performance)

---

**Documento criado por**: NEXUS (AGT-ARC-001) - Solution Architect
**Aprovado por**: JosÃ© LuÃ­s Silva (CTO)
**Data de AprovaÃ§Ã£o**: 2025-10-24
**Status**: âœ… Aprovado
**Impacto**: ğŸ”´ CrÃ­tico (performance Ã© requisito essencial)
